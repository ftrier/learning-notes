{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter\n",
    "\n",
    "The Kalman filter is a powerful mathematical tool used for estimating the state of a dynamic system from a series of noisy measurements. It is widely used in various fields such as robotics, navigation, finance, and control systems due to its ability to provide optimal estimates in real-time.\n",
    "\n",
    "This notebook provides an in-depth exploration of the Kalman filter, including some theoretical foundations and a practical implementation. We will cover the following topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Intuition\n",
    "\n",
    "First, we need to talk about gaussian and the intuition behind them.\n",
    "A Gaussian distribution, also known as a normal distribution, is a way to describe how values are spread out. It is often used to represent real-world data that clusters around a central value.\n",
    "\n",
    "Imagine you are measuring the heights of a large group of people:\n",
    "* Mean ($\\mu$): The average height is 170 cm.\n",
    "* Standard Deviation ($\\sigma$): The standard deviation is 10 cm.\n",
    "\n",
    "Given two gaussian distributions, the resulting Gaussian distribution after addition is:\n",
    "\n",
    "$$ \\mu = \\mu_1 + \\mu_2 $$\n",
    "$$ \\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2} $$\n",
    "\n",
    "Given two gaussian distributions, the resulting Gaussian distribution after multiplication is:\n",
    "\n",
    "$$ \\mu = \\frac{{\\sigma_1^2 \\mu_2 + \\sigma_2^2 \\mu_1}}{{\\sigma_1^2 + \\sigma_2^2}} $$\n",
    "\n",
    "$$ \\sigma = \\frac{\\sigma_1^2 \\sigma_2^2}{\\sigma_1^2 + \\sigma_2^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def plot(self):\n",
    "        x = np.linspace(self.mu - 3*self.sigma, self.mu + 3*self.sigma, 100)\n",
    "        y = np.exp(-0.5 * ((x - self.mu) / self.sigma)**2) / (self.sigma * np.sqrt(2*np.pi))\n",
    "        return x,y\n",
    "\n",
    "    def __add__(self, other):\n",
    "        mu = self.mu + other.mu\n",
    "        sigma = np.sqrt(self.sigma**2 + other.sigma**2)\n",
    "        return Gaussian(mu, sigma)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        mu = (self.sigma**2 * other.mu + other.sigma**2 * self.mu) / (self.sigma**2 + other.sigma**2)\n",
    "        sigma = np.sqrt(self.sigma**2*other.sigma**2 / (self.sigma**2 + other.sigma**2))\n",
    "        return Gaussian(mu, sigma)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'N(mu={self.mu}, sigma={self.sigma})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement = Gaussian(170, 10)\n",
    "plt.plot(*measurement.plot())\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Probability Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the measurement and obtain the same result. This should ideally increase our confidence that the average person's height is indeed 170 cm. Mathematically, we can express this by combining our measurements, such as by multiplying the normal distributions. As a result, the uncertainty decreases (the variance is reduced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_measurement = measurement * measurement\n",
    "plt.plot(*repeated_measurement.plot(), label='Repeated Measurement')\n",
    "plt.plot(*measurement.plot(), label='Single Measurement')\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we take another measurement, and this time, the average height is 200 cm, which is higher than our initial measurement of 170 cm. We would then expect the true average height to lie somewhere between 170 cm and 200 cm. Consequently, the mean shifts towards the new measurement, and the uncertainty decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_2 = Gaussian(200, 5)\n",
    "updated_measurement = measurement * measurement_2\n",
    "plt.plot(*updated_measurement.plot(), label='Updated Measurement')\n",
    "plt.plot(*measurement.plot(), label='Single Measurement')\n",
    "plt.plot(*measurement_2.plot(), label='Measurement 2')\n",
    "plt.xlabel('Height (cm)')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Gaussian to Kalman Filter\n",
    "\n",
    "The Kalman filter uses Gaussian distributions to represent the state and measurements. \n",
    "\n",
    "The flowchart visualizes the algorithm. I have categorized the boxes into three categories:\n",
    "\n",
    "1. Main Steps (Blue): These boxes illustrate the primary steps involved in updating the state.\n",
    "2. Covariances (Yellow): These boxes represent the measure of uncertainty.\n",
    "3. Gain (Green): This central component is depicted in green.\n",
    "\n",
    "Let's consider a practical example where we estimate the position of a moving car. The car accelerates constantly, increasing its speed over time.\n",
    "\n",
    "1. State Estimate: Initially, this can be random. We estimate the car's position and velocity and calculate the uncertainty of this estimate using the covariance.\n",
    "   * $\\mu_{\\text{pred}} = A \\mu_{\\text{prev}}$\n",
    "   * $ \\sigma_{\\text{pred}}^2 = A \\sigma_{\\text{prev}}^2 A^T + Q $ \n",
    "2. Measurement: We measure the car's position and velocity, and optionally, the uncertainty of that measurement.\n",
    "3. Innovation Calculation: We compute the innovation, which is the difference between the estimate and the measurement and the covariance of the innovation $S$.\n",
    "   * $ S = \\sigma_{\\text{pred}}^2 + \\sigma_{\\text{meas}}^2 $\n",
    "   * $  S^{-1} = \\frac{1}{\\sigma_{\\text{pred}}^2 + \\sigma_{\\text{meas}}^2}  $\n",
    "4. Kalman Gain: The gain indicates the reliability of the measurement versus the estimate. A high gain suggests low measurement uncertainty, and vice versa.\n",
    "   * $K = \\frac{\\sigma_{\\text{pred}}^2}{\\sigma_{\\text{pred}}^2 + \\sigma_{\\text{meas}}^2}$, $ 0 \\le K \\le 1$\n",
    "5. Estimate Update: We update our initial estimate using the measurement, with the gain weighing the innovation.\n",
    "   * $\\mu_{\\text{update}} = \\mu_{\\text{pred}} + K (\\mu_{\\text{meas}} - \\mu_{\\text{pred}})$\n",
    "   * $\\sigma_{\\text{update}}^2 = (1 - K) \\sigma_{\\text{pred}}^2$\n",
    "\n",
    "![Kalman Filter](images/kalman-filter.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Tracking\n",
    "\n",
    "This tracking example implements the flowchart from above in a 2-dimensional space. It is a more general version of the equations previously discussed. Could you implement the simplified version of this for a 1-dimensional case? How would it look?\n",
    "\n",
    "Hints\n",
    "* $H$ would be just $1$, since we would be dealing with scalars instead of matrices.\n",
    "* The inverse of a matrix $\\mathbf{A} * \\mathbf{A}^{-1} = \\mathbf{I}$, where $\\mathbf{I}$ is the identity matrix. In the scalar world, this would be expressed as $\\mathbf{v} * \\mathbf{v}^{-1} = 1 = \\frac{\\mathbf{v}}{\\mathbf{v}} $\n",
    "* Remember the chapter about the PCA. The covariance is just the generalization of the variance. And the variance again is just a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1.0\n",
    "steps = 15\n",
    "\n",
    "# The state transition (A) matrix represents a constant velocity model, x_1 = x_0 + v_0 * dt\n",
    "A = np.array([[1, dt],\n",
    "              [0, 1]])\n",
    "\n",
    "# Control input matrix (B) represents the change in velocity controlled by acceleration, u = 0.5 * a * t^2\n",
    "B = np.array([[0.5 * dt**2], [dt]])\n",
    "\n",
    "# state vector, [position; velocity]\n",
    "x = np.array([[0], [0]])\n",
    "\n",
    "# We directly measure the position, so the observation matrix (H) is just a selection matrix\n",
    "H = np.array([[1, 0]])\n",
    "\n",
    "# Process noise covariance (Q), represents the uncertainty in the model\n",
    "Q = np.array([[0.25 * dt**4,    0.5 * dt**3],\n",
    "              [0.5 * dt**3,     dt**2]])\n",
    "\n",
    "# Initial state covariance\n",
    "P = np.eye(2)\n",
    "\n",
    "# Measurement noise covariance (R), represents the uncertainty in the measurements\n",
    "R = np.array([[1]])\n",
    "\n",
    "# Generate truth and noisy measurements\n",
    "true_state = np.zeros((2, steps))\n",
    "measurements = np.zeros(steps)\n",
    "for t in range(1, steps):\n",
    "    true_state[:, t] = np.dot(A, true_state[:, t-1]) + B.flatten()\n",
    "    measurements[t] = true_state[0, t] + np.random.normal(0, 5)\n",
    "\n",
    "estimates = np.zeros((2, steps))\n",
    "gaussians = []\n",
    "\n",
    "for t in range(steps):\n",
    "    # Step 1, State estimate\n",
    "    x = A @ x\n",
    "    P = A @ P @ A.T + Q\n",
    "    gaussians += [Gaussian(x[0, 0], np.sqrt(P[0, 0]))]\n",
    "\n",
    "    # Step 2, Measurement\n",
    "    z = np.array([[measurements[t]]])\n",
    "\n",
    "    # Step 3, Innovation\n",
    "    y = z - H @ x\n",
    "    # S is the innovation covariance, the sum of the measurement covariance and the estimated covariance\n",
    "    S = H @ P @ H.T + R\n",
    "\n",
    "    # Step 4, Kalman Gain\n",
    "    K = P @ H.T @ np.linalg.inv(S)\n",
    "    # Step 5, Update the state estimate\n",
    "    x = x + K @ y\n",
    "    P = (np.eye(2) - K @ H) @ P\n",
    "    estimates[:, t] = x.flatten()\n",
    "\n",
    "plt.plot(true_state[0], label='True Position')\n",
    "plt.plot(measurements, 'r.', label='Measurements')\n",
    "plt.plot(estimates[0], label='Kalman Filter Estimate')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self, gaussians):\n",
    "        self.gaussians = gaussians\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_xlim(-10, 120)\n",
    "        self.ax.set_ylim(0, 0.5)\n",
    "        self.lines, = self.ax.plot(*gaussians[0].plot())\n",
    "\n",
    "    def animate(self, t):\n",
    "        g = self.gaussians[t]\n",
    "        x, y = g.plot()\n",
    "        self.lines.set_data(x, y)\n",
    "        return self.lines,\n",
    "\n",
    "    def plot(self):\n",
    "        return animation.FuncAnimation(self.fig, self.animate, frames=len(self.gaussians), blit=True)\n",
    "\n",
    "ev = Visualizer(gaussians)\n",
    "ev.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# Kubernetes Cheat Sheet

## Key Concepts

* **Pod** = Container + Layer to abstract the underlying container technology
  * Each pod has its own ip address
* **Service** is a static IP address to a pod
  * During replication, a service also functions as a load balancer
* Each pod will have a service; lifetime of pod and service is not related
* **Ingress** is an "external service" which routes requests to services
* **ConfigMap**: external configuration of the application, e.g. DB_URL
* **Secret** like ConfigMap, base64 encoded
* **Volumes** attach a physical storage to a pod
* A **Deployment** is a blueprint on how to create a pod. You can specify the number of replicas of a pod
* A database cannot be replicated using a Deployment
  * **StatefulSet** for stateful apps make sure that database reads/writes are synchronized to avoid data inconsistencies
* A worker node consists of 3 processes:
  * Container runtime
  * Kubelet is a process which handles the pods
  * Kube Proxy forwards the process
* A master node consists of 4 processes:
  * **ApiServer** is a cluster gatway and a gatekeeper to the cluster
  * **Scheduler**: where to put the next pod (Scheduler -> asks Kubelet to schedule)
  * **Controller Manager** detects state changes like pod crashes
  * **Etcd** is a key value store, is a cluster brain, provides information to scheduler about what resources are available

## kubectl

* `kubectl create deployment nginx-depl --image=nginx` which creates:
  * Deployment, Spec for the deployment
    * Replicaset
      * Pod, Spec for the pod
* Consider the template section as the blueprint for the pods
* `kubectl edit deployment >deployment<`
* `kubectl logs >pod<`
* `kubectl exec -it >pod< â€” /bin/bash`
* `kubectl apply/delete -f >file<`
* `kubectl get pod -o wide`
* `kubectl create namespace my-namespace`

## Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongodb-deployment
  labels:
    app: mongodb
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mongodb
  template:
    metadata:
      labels:
        app: mongodb
    spec:
      containers:
        - name: mongodb
          image: mongo
          ports:
            - containerPort: 27017
          env:
            - name: MONGO_INITDB_ROOT_USERNAME
              valueFrom:
                secretKeyRef:
                  name: mongodb-secret
                  key: mongo-root-username
            - name: MONGO_INITDB_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mongodb-secret
                  key: mongo-root-password
--- # separates yaml files
apiVersion: v1
kind: Service
metadata:
  name: mongodb-service
spec:
  selector:
    app: mongodb
  ports:
    - protocol: TCP
      port: 27017       # exposed service port for all pods
      targetPort: 27017 # matches containerPort
---
apiVersion: v1
kind: Secret
metadata:
    name: mongodb-secret
type: Opaque
data:
    mongo-root-username: dXNlcm5hbWU= # echo -n 'username' | base64
    mongo-root-password: cGFzc3dvcmQ= # echo -n 'password' | base64
```

* Each config file has 3 parts
  * Metadata
  * Specification
  * Status comparing desired and actual state, which is automatically generated by Kuberentes
    * This is the self healing feature provided by etcd
* Services have a selector (`app: nginx`) and the deployment has the label `app:nginx`
  * Defines which pods are registered to the service

## Ingress & External Services

* `targetPort` of Service must be same as `containerPort`
* LoadBalacner is external service and opens up `nodePort`
* LoadBalancer is only used **without** Ingress, because Ingress has rules to map an external url to an internal service
* Ingress Controller must be installed in the cluster separately
* This requires a **proxy server** with a public ip address to redirect requests to the ingress controller
* For minikube:

```sh
minikube addons enable ingress
minikube service mongo-express-service
```

## Namespaces

* Namespaces are virtual cluster inside a cluster
* Standard Namespaces
  * `kube-system`: processes kubectl
  * `kube-public`: contains public information, `kubectl cluster info`
  * `kube-node-lease`: heartbeats of nodes
  * `default`

### Grouping

* Logical grouping: Database Namespace, Monitoring Namespace, Nginx Ingress
* Staging and Development Grouping
* Blue/Green Deployment, if they use the same resources
  * Production Blue (is active)
  * Production Green (will be active)
* One Namespace per team

### Limitations

* Cannot use configmaps/secrets between namespaces
* Volume/node cannot be namespaces
* `kubens`/`kubectx` allows to select the default namespace in the shell

## Helm Chart

* Package Manager for Kubernetes
* [ArtifactHub](https://artifacthub.io): Can bundle a complete tech stack
* `values.yaml` contains configuration values
* `chart.yaml` contains metadata
* `charts/` folder contains chart dependencies
* `templates/` contains the actual charts


## Storage

### Requirements

1. Storage does not depend on pod lifecycle
2. Storage must be available on all nodes
3. Storage need to survive if cluster crashes

### Persistent Volumes

* **Persistent Volumes** are a cluster resource like memory, they must exist before pods exist
* Local storage violates requirement 2 and 3, for **database persistency, it is best to create a remote storage**
* Applications do not directly use PV, but have to claim to use volumes: **Persistent Volume Claims**
* PV are not namespaced
* PVC are namespaced
* **Storage Classes** create persistent volumes in the background via a **provisioner**
* Storage Classes are called from the PVC

## Statefulset

* Replicas maintain a sticky identity for each pod
  * Pods are name (Statefulsetname)-(ordinal), master = 0
  * Pods have fixed DNS Name
* Pods are created from the same spec but are not interchangeable
* Only the master pod is allowed to write to a DB, the other workers are only allowed to read
* Pods need to sync the data all the time
* Due to the sticky identity remote storage should be used
